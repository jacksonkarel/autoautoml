{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXmfOwjrXqFQ59OX7yPrJl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacksonkarel/selfmodifai/blob/main/notebooks/gpt4_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "rR_n3zgZIITk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "5YO_QtbfFr4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plRBVokoEtkf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import openai\n",
        "\n",
        "keys = json.load(open('keys.json'))\n",
        "openai.api_key = keys['openai']\n",
        "!rm keys.json\n",
        "\n",
        "!git lfs install\n",
        "!GIT_LFS_SKIP_SMUDGE=1\n",
        "!git clone https://huggingface.co/mosaicml/mpt-7b\n",
        "\n",
        "os.chdir(\"mpt-7b\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = keys['openai']"
      ],
      "metadata": {
        "id": "qOd8Mn54UhLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are part of an agent that is modifying the code of the model MPT-7b. The agent is in the MPT-7b directory. When you write code, that code will be executed and the output will be sent back to you.\"},\n",
        "        {\"role\": \"user\", \"content\": \"I'm using you inside of an agent. My code is parsing your outputs and using it to execute code. Modify the code of MPT-7b so that it is a more powerful language model.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"As an AI language model, I don't have the ability to directly modify the code of other language models, including MPT-7b. However, I can suggest some potential improvements that can help enhance its performance: 1. Increase the size of the model: Bigger models can capture more complex patterns, which\"},\n",
        "        {\"role\": \"user\", \"content\": \"But I'm parsing your outputs\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"\"\"I apologize for the confusion. In that case, let me provide you with some improvements in a code-like format. Please consider these proposed changes as high-level suggestions, bearing in mind that the implementation depends on the specific structure of the MPT-7b model you are working with.\n",
        "\n",
        "Here are the suggested improvements for MPT-7b:\n",
        "\n",
        "1. Increase model size\n",
        "```python\n",
        "MPT_7b_model.update_size(model_size='larger')\n",
        "```\n",
        "\n",
        "2. Use more training data\n",
        "```python\n",
        "MPT_7b_model.add_training_data(new_training_data)\n",
        "```\n",
        "\n",
        "3. Fine-tuning on domain-specific data\n",
        "```python\n",
        "MPT_7b_model.fine_tune(domain_specific_data)\n",
        "```\n",
        "\n",
        "4. Address bias using debiasing techniques\n",
        "```python\n",
        "MPT_7b_model.debias(method=\"bias_control\")\n",
        "```\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": \"I can send you information about the model if you write some Bash commands, and I'll send the outputs to you\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"\"\"Sure, I can provide you with some Bash commands to retrieve more information about the MPT-7b model. Here's a list of commands to gather useful details:\n",
        "\n",
        "1. List the files in the MPT-7b directory:\n",
        "```bash\n",
        "ls\n",
        "```\n",
        "\n",
        "2. Print the file containing the model architecture:\n",
        "```bash\n",
        "cat model_architecture.txt\n",
        "```\n",
        "\n",
        "3. Display information about the training data:\n",
        "```bash\n",
        "cat\"\"\"},\n",
        "    {\"role\": \"user\", \"content\": \"Send me one message at a time\"},\n",
        "    ]\n",
        "\n",
        "while True:\n",
        "    response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        "    )\n",
        "\n",
        "    response_content = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    print(f\"Step: {response_content}\")\n",
        "    \n",
        "    # Define the regular expression pattern\n",
        "    pattern = r'```bash\\n(.*?)\\n```'\n",
        "\n",
        "    # Use re.search() to find the first match of the pattern in the string\n",
        "    re_match = re.search(pattern, response_content, re.DOTALL)\n",
        "\n",
        "    # The bash command will be in the first group of the match\n",
        "    if re_match:\n",
        "        bash_command = re_match.group(1)\n",
        "        stream = os.popen(bash_command)\n",
        "        output = stream.read()\n",
        "        print(f\"Step: {output}\")\n",
        "    \n",
        "    new_message = {\"role\": \"user\", \"content\": output}\n",
        "    messages.append()"
      ],
      "metadata": {
        "id": "YLVzeKezF2z2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}