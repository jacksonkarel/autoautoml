{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacksonkarel/selfmodifai/blob/main/notebooks/gpt4_agent_modify_alpaca_lora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR_n3zgZIITk"
      },
      "outputs": [],
      "source": [
        "!pip install openai transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YO_QtbfFr4o"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plRBVokoEtkf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "\n",
        "keys = json.load(open('keys.json'))\n",
        "openai.api_key = keys['openai']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GIT_EMAIL\"] = keys[\"git_email\"]\n",
        "os.environ[\"GIT_USERNAME\"] = keys[\"git_username\"]"
      ],
      "metadata": {
        "id": "C3Y86UhYXSCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!rm -rf /root/.ssh\n",
        "\n",
        "!mkdir /root/.ssh\n",
        "\n",
        "!tar xvzf ssh.tar.gz\n",
        "\n",
        "!cp ssh-colab/* /root/.ssh && rm -rf ssh-colab && rm -rf ssh.tar.gz\n",
        "!chmod 700 .shh\n",
        "\n",
        "!touch /root/.ssh/known_hosts\n",
        "!ssh-keyscan github.com >> /root/.ssh/known_hosts\n",
        "!chmod 644 /root/.ssh/known_hosts\n",
        "\n",
        "!git config --global user.email GIT_EMAIL\n",
        "!git config --global user.name GIT_USERNAME\n",
        "!git clone git@github.com:jacksonkarel/selfmodifai-alpaca-lora.git\n",
        "os.chdir(\"selfmodifai-alpaca-lora\")"
      ],
      "metadata": {
        "id": "AWY-kZDGvGX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "access_token = keys[\"github_access_token\"]\n",
        "\n",
        "os.environ[\"GITHUB_REPO\"] = f\"https://{access_token}@github.com/jacksonkarel/selfmodifai-alpaca-lora.git\"\n",
        "\n",
        "!git config --global user.email GIT_EMAIL\n",
        "!git config --global user.name GIT_USERNAME\n",
        "!git clone GITHUB_REPO\n",
        "os.chdir(\"selfmodifai-alpaca-lora\")"
      ],
      "metadata": {
        "id": "ntGyYoah42pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "messages = [{'role': 'system', 'content': 'You are part of an agent that is modifying the code of the model MPT-7b. The agent is in the MPT-7b directory. When you write code, that code will be executed and the output will be sent back to you.'}, {'role': 'user', 'content': \"I'm using you inside of an agent. My code is parsing your outputs and using it to execute code. Modify the code of MPT-7b so that it is a more powerful language model.\"}, {'role': 'assistant', 'content': \"As an AI language model, I don't have the ability to directly modify the code of other language models, including MPT-7b. However, I can suggest some potential improvements that can help enhance its performance: 1. Increase the size of the model: Bigger models can capture more complex patterns, which\"}, {'role': 'user', 'content': \"But I'm parsing your outputs\"}, {'role': 'assistant', 'content': 'I apologize for the confusion. In that case, let me provide you with some improvements in a code-like format. Please consider these proposed changes as high-level suggestions, bearing in mind that the implementation depends on the specific structure of the MPT-7b model you are working with.\\n\\nHere are the suggested improvements for MPT-7b:\\n\\n1. Increase model size\\n```python\\nMPT_7b_model.update_size(model_size=\\'larger\\')\\n```\\n\\n2. Use more training data\\n```python\\nMPT_7b_model.add_training_data(new_training_data)\\n```\\n\\n3. Fine-tuning on domain-specific data\\n```python\\nMPT_7b_model.fine_tune(domain_specific_data)\\n```\\n\\n4. Address bias using debiasing techniques\\n```python\\nMPT_7b_model.debias(method=\"bias_control\")\\n```'}, {'role': 'user', 'content': \"I can send you information about the model if you write some Bash commands, and I'll send the outputs to you\"}, {'role': 'assistant', 'content': \"Sure, I can provide you with some Bash commands to retrieve more information about the MPT-7b model. Here's a list of commands to gather useful details:\\n\\n1. List the files in the MPT-7b directory:\\n```bash\\nls\\n```\\n\\n2. Print the file containing the model architecture:\\n```bash\\ncat model_architecture.txt\\n```\\n\\n3. Display information about the training data:\\n```bash\\ncat\"}, {'role': 'user', 'content': 'Send me one message at a time'}]\n",
        "\n",
        "with open('messages.json', 'w') as outfile:\n",
        "    json.dump(messages, outfile)"
      ],
      "metadata": {
        "id": "7n06IHjGhneU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('messages.json') as json_file:\n",
        "    messages = json.load(json_file)\n",
        "\n",
        "messages.pop()\n",
        "\n",
        "with open('messages.json', 'w') as outfile:\n",
        "    json.dump(messages, outfile)"
      ],
      "metadata": {
        "id": "sQaqZ11EjgV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLVzeKezF2z2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "from transformers import pipeline\n",
        "\n",
        "def update_messages(content, role, messages):\n",
        "    new_message = {\"role\": role, \"content\": content}\n",
        "    messages.append(new_message)\n",
        "    with open('messages.json', 'w') as outfile:\n",
        "        json.dump(messages, outfile)\n",
        "    \n",
        "    print(f\"Step: {content}\")\n",
        "    return messages\n",
        "\n",
        "def gpt4_agent(learn_dir=False):\n",
        "    with open('messages.json') as json_file:\n",
        "        messages = json.load(json_file)\n",
        "\n",
        "    while True:\n",
        "        response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=messages\n",
        "        )\n",
        "\n",
        "        response_content = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "        \n",
        "        messages = update_messages(response_content, \"assistant\", messages)\n",
        "        \n",
        "        # Define the regular expression pattern\n",
        "        pattern = r'```bash\\n(.*?)\\n```'\n",
        "\n",
        "        matches = re.findall(pattern, response_content, re.DOTALL)\n",
        "\n",
        "        python_content = re.search(r'```python\\n(.*?)\\n```', response_content)\n",
        "\n",
        "        python_prompt = \"Write bash commands to implement those changes in the Python files.\"\n",
        "\n",
        "        if matches:\n",
        "        # matches is now a list of all bash commands in the string\n",
        "            for bash_command in matches:\n",
        "                stream = os.popen(bash_command)\n",
        "                output = stream.read()\n",
        "            \n",
        "            if learn_dir:\n",
        "                content = output\n",
        "            \n",
        "            elif python_content:\n",
        "                content = python_prompt\n",
        "\n",
        "            else:\n",
        "                content = \"Ok, did that\"\n",
        "        \n",
        "        elif python_content:\n",
        "            content = python_prompt\n",
        "\n",
        "        else:\n",
        "            learn_dir = False\n",
        "            classifier = pipeline(\"zero-shot-classification\")\n",
        "            labels = [\"suggestion for what to do next\", \"question\"]\n",
        "            results = classifier(sequences=response_content, candidate_labels=labels, hypothesis_template=\"This text is a {}\")\n",
        "\n",
        "            if results[\"scores\"][0] > 0.70:\n",
        "                if results[\"labels\"][0] == \"suggestion for what to do next\":\n",
        "                    content = \"Create bash commands that implement those changes. Give me them one by one.\"\n",
        "                \n",
        "                else:\n",
        "                    content = \"My goal is to improve the model architecture of Alpaca-LoRA to make it a more powerful language model. Find the answer to that question in that context. If you can't, try another step in improving the language model.\"\n",
        "            \n",
        "        \n",
        "        messages = update_messages(content, \"user\", messages)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt4_agent(True)"
      ],
      "metadata": {
        "id": "PDMCx-8JTmCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "PtpLlGfq5HJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACE_TOKEN\"] = keys[\"hugging_face\"]\n",
        "!huggingface-cli login --token $HUGGINGFACE_TOKEN"
      ],
      "metadata": {
        "id": "Ahm6fF355N6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"messages.json\",\n",
        "    path_in_repo=\"messages.json\",\n",
        "    repo_id=\"jacksonkarel/selfmodifai-mpt-7b\"\n",
        ")"
      ],
      "metadata": {
        "id": "GkGf5yNh77cX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU/yWjJZ3a4RHBCFDsnQqb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}